// exo5.2

#include <mpi.h>
#include <iostream>
#include <vector>
#include <cstdlib>  // pour rand() et srand()
#include <ctime>    // pour time()

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);

    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    // On veut exactement 5 processus(non)
	/*
    if (size != 5) {
        if (rank == 0) std::cerr << "Erreur : ce programme n√©cessite exactement 5 processus.\n";
        MPI_Finalize();
        return 1;
    }
	*/

    const long N = 1000000; // taille du tableau total
    const long chunk_size = N / size; // taille de chaque sous-tableau

    std::vector<int> full_array; // seulement utilis√© par le ma√Ætre

    // Initialisation al√©atoire
    srand(time(NULL) + rank); // seed diff√©rente par processus

    // üîπ Processus ma√Ætre cr√©e le tableau complet
    if (rank == 0) {
        full_array.resize(N);
        for (long i = 0; i < N; i++) {
            full_array[i] = rand() % 1000; // valeurs al√©atoires entre 0 et 999
        }
    }

    // üîπ Chaque processus pr√©pare son sous-tableau
    std::vector<int> local_array(chunk_size);

    // üîπ R√©partition du tableau avec MPI_Scatter
    // Les N √©l√©ments de full_array sont d√©coup√©s en `size` morceaux
    MPI_Scatter(
        full_array.data(),       // buffer source (sur le ma√Ætre)
        chunk_size,              // nombre d'√©l√©ments envoy√©s √† chaque processus
        MPI_INT,                 // type des √©l√©ments
        local_array.data(),      // buffer de r√©ception local
        chunk_size,              // nombre d'√©l√©ments re√ßus
        MPI_INT,
        0,                       // rang du processus ma√Ætre
        MPI_COMM_WORLD
    );

    // üîπ Le ma√Ætre choisit le nombre √† chercher
    int x;
    if (rank == 0) {
        x = rand() % 1000; // nombre al√©atoire entre 0 et 999
        std::cout << "Nombre √† rechercher x = " << x << std::endl;
    }

    // üîπ Diffuser x √† tous les processus avec MPI_Bcast
    MPI_Bcast(&x, 1, MPI_INT, 0, MPI_COMM_WORLD);

    // üîπ Chaque processus compte les occurrences locales de x
    int local_count = 0;
    for (long i = 0; i < chunk_size; i++) {
        if (local_array[i] == x) local_count++;
    }

    // üîπ Le ma√Ætre collecte les r√©sultats de tous les processus
    if (rank == 0) {
        std::vector<int> counts(size);
        counts[0] = local_count; // ajout de son propre r√©sultat

        for (int src = 1; src < size; src++) {
            MPI_Recv(&counts[src], 1, MPI_INT, src, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        }

        // Affichage du nombre d'occurrences par processus
        for (int i = 0; i < size; i++) {
            std::cout << "Processus " << i << " a trouv√© " << counts[i] << " occurrences de " << x << std::endl;
        }

    } else {
        // Les esclaves envoient leur r√©sultat au ma√Ætre
        MPI_Send(&local_count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);
    }

    MPI_Finalize();
    return 0;
}
